{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\programdata\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import backend as K\n",
    "\n",
    "### Custom Py Script\n",
    "import Pipeline\n",
    "import Toxic_Models\n",
    "import Model_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = Pipeline.load_emb_model('./emb_model/crawl-300d-2M.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "submission = pd.read_csv(\"./input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### preprocessing parameter\n",
    "maxlen = 180\n",
    "max_features = 100000       \n",
    "embed_size = 300\n",
    "\n",
    "\n",
    "### model parameter\n",
    "cell_size = 64                   ### Cell unit size\n",
    "cell_type_GRU = True             ### Cell Type: GRU/LSTM\n",
    "filter_size = 64\n",
    "kernel_size = 2\n",
    "stride = 1 \n",
    "\n",
    "### K-fold cross-validation\n",
    "k= 5\n",
    "kf = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "### training protocol\n",
    "epochs= 13\n",
    "batch_size = 128\n",
    "lr_s = True                        ### Use of Learning Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data is loaded\n",
      "=== Data is preprocessed\n",
      "=== Embedding Matrix is loaded\n"
     ]
    }
   ],
   "source": [
    "X_tr, Y_tr, X_te, emb_matrix = Pipeline.load_data_2path(emb_model, max_features = max_features, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = Toxic_Models.get_model_rnn_cnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU, filter_size=filter_size, kernel_size=kernel_size, stride=stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(mdl, to_file='model_rnn_cnn.png')\n",
    "SVG(model_to_dot(mdl).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_rnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnncnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_rnn_cnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU, \n",
    "                                         filter_size=filter_size, kernel_size=kernel_size, stride=stride)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "\n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnncaps'\n",
    "\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "for train_index, val_index in kf.split(datas[0][0], datas[1]):\n",
    "    cv_x_tr = [X_t_pre[train_index], X_t_post[train_index]]\n",
    "    cv_x_val = [X_t_pre[val_index], X_t_post[val_index]]\n",
    "    cv_y_tr = Y_t[train_index]\n",
    "    cv_y_te = Y_t[val_index]\n",
    "\n",
    "    mdl = Toxic_Models.get_model_rnn_caps(datas[3], cell_size=80, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    preds = Model_trainer.model_train_cv(mdl, cv_x_tr, cv_x_val,cv_y_tr, cv_y_te, datas[2], model_name, batch_size=128, epochs=epochs, lr=lr)\n",
    "    res += preds[0]\n",
    "    oofs.append(preds[1])\n",
    "    \n",
    "res = res/k\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 127656 samples, validate on 31915 samples\n",
      "Epoch 1/13\n",
      " - 75s - loss: 0.0605 - binary_crossentropy: 0.0605 - acc: 0.9790 - val_loss: 0.0454 - val_binary_crossentropy: 0.0454 - val_acc: 0.9825\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.982217 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04540, saving model to best_model.hdf5\n",
      "Epoch 2/13\n",
      " - 70s - loss: 0.0434 - binary_crossentropy: 0.0434 - acc: 0.9833 - val_loss: 0.0419 - val_binary_crossentropy: 0.0419 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.989128 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04540 to 0.04191, saving model to best_model.hdf5\n",
      "Epoch 3/13\n",
      " - 70s - loss: 0.0400 - binary_crossentropy: 0.0400 - acc: 0.9843 - val_loss: 0.0396 - val_binary_crossentropy: 0.0396 - val_acc: 0.9842\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.990106 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04191 to 0.03957, saving model to best_model.hdf5\n",
      "Epoch 4/13\n",
      " - 72s - loss: 0.0380 - binary_crossentropy: 0.0380 - acc: 0.9851 - val_loss: 0.0403 - val_binary_crossentropy: 0.0403 - val_acc: 0.9841\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.990229 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/13\n",
      " - 71s - loss: 0.0365 - binary_crossentropy: 0.0365 - acc: 0.9856 - val_loss: 0.0392 - val_binary_crossentropy: 0.0392 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.990574 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03957 to 0.03925, saving model to best_model.hdf5\n",
      "Epoch 6/13\n",
      " - 71s - loss: 0.0354 - binary_crossentropy: 0.0354 - acc: 0.9860 - val_loss: 0.0389 - val_binary_crossentropy: 0.0389 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.990610 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03925 to 0.03887, saving model to best_model.hdf5\n",
      "Epoch 7/13\n",
      " - 71s - loss: 0.0347 - binary_crossentropy: 0.0347 - acc: 0.9862 - val_loss: 0.0388 - val_binary_crossentropy: 0.0388 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.990590 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03887 to 0.03884, saving model to best_model.hdf5\n",
      "Epoch 8/13\n",
      " - 71s - loss: 0.0409 - binary_crossentropy: 0.0409 - acc: 0.9840 - val_loss: 0.0417 - val_binary_crossentropy: 0.0417 - val_acc: 0.9836\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.989920 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/13\n",
      " - 71s - loss: 0.0342 - binary_crossentropy: 0.0342 - acc: 0.9864 - val_loss: 0.0385 - val_binary_crossentropy: 0.0385 - val_acc: 0.9845\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.990909 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03884 to 0.03845, saving model to best_model.hdf5\n",
      "Epoch 10/13\n",
      " - 70s - loss: 0.0321 - binary_crossentropy: 0.0321 - acc: 0.9872 - val_loss: 0.0383 - val_binary_crossentropy: 0.0383 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.991029 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03845 to 0.03832, saving model to best_model.hdf5\n",
      "Epoch 11/13\n",
      " - 71s - loss: 0.0317 - binary_crossentropy: 0.0317 - acc: 0.9873 - val_loss: 0.0383 - val_binary_crossentropy: 0.0383 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.991051 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03832 to 0.03829, saving model to best_model.hdf5\n",
      "Epoch 12/13\n",
      " - 70s - loss: 0.0315 - binary_crossentropy: 0.0315 - acc: 0.9874 - val_loss: 0.0383 - val_binary_crossentropy: 0.0383 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.990980 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/13\n",
      " - 70s - loss: 0.0312 - binary_crossentropy: 0.0312 - acc: 0.9876 - val_loss: 0.0383 - val_binary_crossentropy: 0.0383 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.990996 \n",
      "\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03829 to 0.03827, saving model to best_model.hdf5\n",
      "31915/31915 [==============================] - 7s 225us/step\n",
      "153164/153164 [==============================] - 36s 235us/step\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/13\n",
      " - 72s - loss: 0.0615 - binary_crossentropy: 0.0615 - acc: 0.9786 - val_loss: 0.0460 - val_binary_crossentropy: 0.0460 - val_acc: 0.9825\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.981507 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04598, saving model to best_model.hdf5\n",
      "Epoch 2/13\n",
      " - 70s - loss: 0.0435 - binary_crossentropy: 0.0435 - acc: 0.9834 - val_loss: 0.0426 - val_binary_crossentropy: 0.0426 - val_acc: 0.9833\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.987461 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04598 to 0.04257, saving model to best_model.hdf5\n",
      "Epoch 3/13\n",
      " - 70s - loss: 0.0402 - binary_crossentropy: 0.0402 - acc: 0.9842 - val_loss: 0.0402 - val_binary_crossentropy: 0.0402 - val_acc: 0.9845\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.989076 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04257 to 0.04017, saving model to best_model.hdf5\n",
      "Epoch 4/13\n",
      " - 70s - loss: 0.0380 - binary_crossentropy: 0.0380 - acc: 0.9849 - val_loss: 0.0402 - val_binary_crossentropy: 0.0402 - val_acc: 0.9843\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.989312 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/13\n",
      " - 71s - loss: 0.0364 - binary_crossentropy: 0.0364 - acc: 0.9855 - val_loss: 0.0398 - val_binary_crossentropy: 0.0398 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.989733 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.04017 to 0.03979, saving model to best_model.hdf5\n",
      "Epoch 6/13\n",
      " - 71s - loss: 0.0352 - binary_crossentropy: 0.0352 - acc: 0.9860 - val_loss: 0.0393 - val_binary_crossentropy: 0.0393 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.989901 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03979 to 0.03933, saving model to best_model.hdf5\n",
      "Epoch 7/13\n",
      " - 70s - loss: 0.0346 - binary_crossentropy: 0.0346 - acc: 0.9863 - val_loss: 0.0392 - val_binary_crossentropy: 0.0392 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.989879 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03933 to 0.03917, saving model to best_model.hdf5\n",
      "Epoch 8/13\n",
      " - 71s - loss: 0.0411 - binary_crossentropy: 0.0411 - acc: 0.9838 - val_loss: 0.0403 - val_binary_crossentropy: 0.0403 - val_acc: 0.9842\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.989348 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/13\n",
      " - 70s - loss: 0.0343 - binary_crossentropy: 0.0343 - acc: 0.9862 - val_loss: 0.0390 - val_binary_crossentropy: 0.0390 - val_acc: 0.9849\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.990230 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03917 to 0.03897, saving model to best_model.hdf5\n",
      "Epoch 10/13\n",
      " - 71s - loss: 0.0321 - binary_crossentropy: 0.0321 - acc: 0.9871 - val_loss: 0.0388 - val_binary_crossentropy: 0.0388 - val_acc: 0.9851\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.990256 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03897 to 0.03883, saving model to best_model.hdf5\n",
      "Epoch 11/13\n",
      " - 70s - loss: 0.0315 - binary_crossentropy: 0.0315 - acc: 0.9873 - val_loss: 0.0389 - val_binary_crossentropy: 0.0389 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.990233 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 12/13\n",
      " - 69s - loss: 0.0313 - binary_crossentropy: 0.0313 - acc: 0.9874 - val_loss: 0.0391 - val_binary_crossentropy: 0.0391 - val_acc: 0.9848\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.990197 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/13\n",
      " - 69s - loss: 0.0312 - binary_crossentropy: 0.0312 - acc: 0.9875 - val_loss: 0.0390 - val_binary_crossentropy: 0.0390 - val_acc: 0.9849\n",
      "\n",
      " ROC-AUC - epoch: 13 - score: 0.990194 \n",
      "\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "31914/31914 [==============================] - 7s 222us/step\n",
      "153164/153164 [==============================] - 34s 222us/step\n",
      "Train on 127657 samples, validate on 31914 samples\n",
      "Epoch 1/13\n",
      " - 71s - loss: 0.0642 - binary_crossentropy: 0.0642 - acc: 0.9780 - val_loss: 0.0482 - val_binary_crossentropy: 0.0482 - val_acc: 0.9823\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.976959 \n",
      "\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04823, saving model to best_model.hdf5\n",
      "Epoch 2/13\n",
      " - 69s - loss: 0.0449 - binary_crossentropy: 0.0449 - acc: 0.9829 - val_loss: 0.0418 - val_binary_crossentropy: 0.0418 - val_acc: 0.9838\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.984983 \n",
      "\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04823 to 0.04180, saving model to best_model.hdf5\n",
      "Epoch 3/13\n",
      " - 69s - loss: 0.0414 - binary_crossentropy: 0.0414 - acc: 0.9839 - val_loss: 0.0394 - val_binary_crossentropy: 0.0394 - val_acc: 0.9846\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.987117 \n",
      "\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.04180 to 0.03938, saving model to best_model.hdf5\n",
      "Epoch 4/13\n",
      " - 69s - loss: 0.0392 - binary_crossentropy: 0.0392 - acc: 0.9845 - val_loss: 0.0392 - val_binary_crossentropy: 0.0392 - val_acc: 0.9846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.988066 \n",
      "\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03938 to 0.03918, saving model to best_model.hdf5\n",
      "Epoch 5/13\n",
      " - 69s - loss: 0.0374 - binary_crossentropy: 0.0374 - acc: 0.9852 - val_loss: 0.0382 - val_binary_crossentropy: 0.0382 - val_acc: 0.9852\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.988472 \n",
      "\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.03918 to 0.03821, saving model to best_model.hdf5\n",
      "Epoch 6/13\n",
      " - 69s - loss: 0.0365 - binary_crossentropy: 0.0365 - acc: 0.9855 - val_loss: 0.0380 - val_binary_crossentropy: 0.0380 - val_acc: 0.9850\n",
      "\n",
      " ROC-AUC - epoch: 6 - score: 0.988636 \n",
      "\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.03821 to 0.03799, saving model to best_model.hdf5\n",
      "Epoch 7/13\n",
      " - 72s - loss: 0.0358 - binary_crossentropy: 0.0358 - acc: 0.9857 - val_loss: 0.0378 - val_binary_crossentropy: 0.0378 - val_acc: 0.9851\n",
      "\n",
      " ROC-AUC - epoch: 7 - score: 0.988753 \n",
      "\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.03799 to 0.03781, saving model to best_model.hdf5\n",
      "Epoch 8/13\n",
      " - 74s - loss: 0.0415 - binary_crossentropy: 0.0415 - acc: 0.9837 - val_loss: 0.0402 - val_binary_crossentropy: 0.0402 - val_acc: 0.9844\n",
      "\n",
      " ROC-AUC - epoch: 8 - score: 0.989068 \n",
      "\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/13\n",
      " - 75s - loss: 0.0351 - binary_crossentropy: 0.0351 - acc: 0.9860 - val_loss: 0.0374 - val_binary_crossentropy: 0.0374 - val_acc: 0.9853\n",
      "\n",
      " ROC-AUC - epoch: 9 - score: 0.990186 \n",
      "\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.03781 to 0.03737, saving model to best_model.hdf5\n",
      "Epoch 10/13\n",
      " - 74s - loss: 0.0330 - binary_crossentropy: 0.0330 - acc: 0.9867 - val_loss: 0.0374 - val_binary_crossentropy: 0.0374 - val_acc: 0.9854\n",
      "\n",
      " ROC-AUC - epoch: 10 - score: 0.990181 \n",
      "\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03737 to 0.03735, saving model to best_model.hdf5\n",
      "Epoch 11/13\n",
      " - 76s - loss: 0.0326 - binary_crossentropy: 0.0326 - acc: 0.9870 - val_loss: 0.0373 - val_binary_crossentropy: 0.0373 - val_acc: 0.9854\n",
      "\n",
      " ROC-AUC - epoch: 11 - score: 0.990235 \n",
      "\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03735 to 0.03729, saving model to best_model.hdf5\n",
      "Epoch 12/13\n",
      " - 78s - loss: 0.0324 - binary_crossentropy: 0.0324 - acc: 0.9870 - val_loss: 0.0373 - val_binary_crossentropy: 0.0373 - val_acc: 0.9854\n",
      "\n",
      " ROC-AUC - epoch: 12 - score: 0.990210 \n",
      "\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/13\n",
      " - 76s - loss: 0.0321 - binary_crossentropy: 0.0321 - acc: 0.9871 - val_loss: 0.0374 - val_binary_crossentropy: 0.0374 - val_acc: 0.9853\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e3360ae35e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n\u001b[0;32m     10\u001b[0m                                              \u001b[0my_tra\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mY_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mY_tr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_te\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                              model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mres\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0moofs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive\\code\\ipython\\kaggle\\toxic\\Model_trainer.py\u001b[0m in \u001b[0;36mmodel_train_cv\u001b[1;34m(model, X_tra, X_val, y_tra, y_val, x_test, model_name, batch_size, epochs, lr_schedule)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val),\n\u001b[1;32m---> 33\u001b[1;33m                              callbacks = [RocAuc, lr_s, check_point], verbose=2)\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'== no learing schedule'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1253\u001b[0m                             \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m                                 \u001b[0mepoch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1255\u001b[1;33m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1257\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m             \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\OneDrive\\code\\ipython\\kaggle\\toxic\\Model_trainer.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[1;34m(self, epoch, logs)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1833\u001b[0m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1834\u001b[0m         return self._predict_loop(f, ins, batch_size=batch_size,\n\u001b[1;32m-> 1835\u001b[1;33m                                   verbose=verbose, steps=steps)\n\u001b[0m\u001b[0;32m   1836\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1837\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[1;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[0;32m   1322\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mins\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m                     \u001b[1;31m# Do not slice the training phase flag.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1326\u001b[0m                     \u001b[0mins_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_slice_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_slice_arrays\u001b[1;34m(arrays, start, stop)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\programdata\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'shape'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mstop\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = '2rnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_2rnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '2rnncnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_2rnn_cnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU, \n",
    "                                         filter_size=filter_size, kernel_size=kernel_size, stride=stride)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "\n",
    "res = res/k\n",
    "    \n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn2cnndr'\n",
    "\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "for train_index, val_index in kf.split(datas[0][0], datas[1]):\n",
    "    cv_x_tr = [X_t_pre[train_index], X_t_post[train_index]]\n",
    "    cv_x_val = [X_t_pre[val_index], X_t_post[val_index]]\n",
    "    cv_y_tr = Y_t[train_index]\n",
    "    cv_y_te = Y_t[val_index]\n",
    "    \n",
    "    mdl = Toxic_Models.get_model_rnn2_cnn_directlink(datas[3], cell_size=80, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    preds = Model_trainer.model_train_cv(mdl, cv_x_tr, cv_x_val,cv_y_tr, cv_y_te, datas[2], model_name, batch_size=256, epochs=epochs, lr=lr)\n",
    "    res += preds[0]\n",
    "    oofs.append(preds[1])\n",
    "                                        \n",
    "res = res/k\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "                                        \n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn2cnn32dr'\n",
    "\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "for train_index, val_index in kf.split(datas[0][0], datas[1]):\n",
    "    cv_x_tr = [X_t_pre[train_index], X_t_post[train_index]]\n",
    "    cv_x_val = [X_t_pre[val_index], X_t_post[val_index]]\n",
    "    cv_y_tr = Y_t[train_index]\n",
    "    cv_y_te = Y_t[val_index]\n",
    "    \n",
    "    mdl = Toxic_Models.get_model_rnn2_cnn_directlink(datas[3], cell_size=80, maxlen=maxlen, cell_type_GRU=cell_type_GRU, kernel_size=3, stride=2)\n",
    "    preds = Model_trainer.model_train_cv(mdl, cv_x_tr, cv_x_val,cv_y_tr, cv_y_te, datas[2], model_name, batch_size=256, epochs=epochs, lr=lr)\n",
    "    res += preds[0]\n",
    "    oofs.append(preds[1])\n",
    "                                        \n",
    "res = res/k\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "                                        \n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dualrnn2cnndr'\n",
    "\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "for train_index, val_index in kf.split(datas[0][0], datas[1]):\n",
    "    cv_x_tr = [X_t_pre[train_index], X_t_post[train_index]]\n",
    "    cv_x_val = [X_t_pre[val_index], X_t_post[val_index]]\n",
    "    cv_y_tr = Y_t[train_index]\n",
    "    cv_y_te = Y_t[val_index]\n",
    "    \n",
    "    mdl = Toxic_Models.get_model_dual_rnn2_cnn_directlink(datas[3], cell_size=80, maxlen=maxlen, cell_type_GRU=True)\n",
    "    preds = Model_trainer.model_train_cv(mdl, cv_x_tr, cv_x_val,cv_y_tr, cv_y_te, datas[2], model_name, batch_size=256, epochs=epochs, lr=lr)\n",
    "    res += preds[0]\n",
    "    oofs.append(preds[1])\n",
    "                                        \n",
    "res = res/k\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "                                        \n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'dualrnn2cnn32dr'\n",
    "\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "for train_index, val_index in kf.split(datas[0][0], datas[1]):\n",
    "    cv_x_tr = [X_t_pre[train_index], X_t_post[train_index]]\n",
    "    cv_x_val = [X_t_pre[val_index], X_t_post[val_index]]\n",
    "    cv_y_tr = Y_t[train_index]\n",
    "    cv_y_te = Y_t[val_index]\n",
    "    \n",
    "    mdl = Toxic_Models.get_model_dual_rnn2_cnn_directlink(datas[3], cell_size=80, maxlen=maxlen, cell_type_GRU=True)\n",
    "    preds = Model_trainer.model_train_cv(mdl, cv_x_tr, cv_x_val,cv_y_tr, cv_y_te, datas[2], model_name, batch_size=256, epochs=epochs, lr=lr)\n",
    "    res += preds[0]\n",
    "    oofs.append(preds[1])\n",
    "                                        \n",
    "res = res/k\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "                                        \n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
