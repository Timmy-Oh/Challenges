{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from keras import backend as K\n",
    "\n",
    "### Custom Py Script from src folder\n",
    "from src import Pipeline, Toxic_Models, Model_trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Pretrained Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_model = Pipeline.load_emb_model('./emb_model/crawl-300d-2M.vec')        # FastText Embeddings\n",
    "emb_model = Pipeline.load_emb_model('./emb_model/glove.840B.300d.txt')    # Glove Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### classes names\n",
    "list_classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "### preprocessing parameter\n",
    "maxlen = 180\n",
    "max_features = 100000       \n",
    "embed_size = 300\n",
    "\n",
    "\n",
    "### model parameter\n",
    "cell_size = 64                   ### Cell unit size\n",
    "cell_type_GRU = True             ### Cell Type: GRU/LSTM\n",
    "filter_size = 64\n",
    "kernel_size = 2\n",
    "stride = 1 \n",
    "\n",
    "### K-fold cross-validation\n",
    "k= 5\n",
    "kf = KFold(n_splits=k, shuffle=False)\n",
    "\n",
    "### training protocol\n",
    "epochs= 13\n",
    "batch_size = 128\n",
    "lr_s = True                        ### Use of Learning Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"./input/sample_submission.csv\")\n",
    "X_tr, Y_tr, X_te, emb_matrix = Pipeline.load_data_2path(emb_model, max_features = max_features, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_rnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "    time.sleep(20)\n",
    "    \n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnncnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_rnn_cnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU, \n",
    "                                         filter_size=filter_size, kernel_size=kernel_size, stride=stride)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "    time.sleep(20)\n",
    "\n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'rnn_caps'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_rnn_caps(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "    time.sleep(20)\n",
    "    \n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '2rnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_2rnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "    time.sleep(20)\n",
    "    \n",
    "res = res/k\n",
    "    \n",
    "\n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = '2rnncnn'\n",
    "\n",
    "### ================================================================== ###\n",
    "oofs = []\n",
    "res = np.zeros_like(submission[list_classes])\n",
    "\n",
    "for train_index, val_index in kf.split(X_tr[0], Y_tr):\n",
    "    mdl = Toxic_Models.get_model_2rnn_cnn(emb_matrix, cell_size=cell_size, maxlen=maxlen, cell_type_GRU=cell_type_GRU, \n",
    "                                         filter_size=filter_size, kernel_size=kernel_size, stride=stride)\n",
    "    pred, oof = Model_trainer.model_train_cv(mdl, X_tra = [X_tr[0][train_index], X_tr[1][train_index]], X_val = [X_tr[0][val_index], X_tr[1][val_index]],\n",
    "                                             y_tra=  Y_tr[train_index], y_val= Y_tr[val_index], x_test=X_te, \n",
    "                                             model_name=model_name, batch_size=batch_size, epochs=epochs, lr_schedule=lr_s)\n",
    "    res += pred\n",
    "    oofs.append(oof)\n",
    "    K.clear_session()\n",
    "    time.sleep(20)\n",
    "\n",
    "res = res/k\n",
    "    \n",
    "### Collect result & Report\n",
    "submission[list_classes] = res\n",
    "submission.to_csv(\"submission_{}.csv\".format(model_name), index = False)\n",
    "\n",
    "np_oofs = np.array(oofs)\n",
    "pd_oofs = pd.DataFrame(np.concatenate(np_oofs), columns=list_classes)\n",
    "pd_oofs.to_csv(\"oofs_{}.csv\".format(model_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
